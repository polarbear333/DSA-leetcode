
## What Is Learning?

Machine learning algorithms used past experience/data to identify patterns, and use these insights to make predictions or decisions. For example, when rats encounter food items that smell, they will first eat very small amount. If it produces an ill effect, the animal predicts that it will also have a negative effect when encountered in the future.

While this "learn by memorizing approach" is sometimes useful, it lacks an important aspect of learning systems - the ability to label unseen data. A successful learner should be able to progress from individual examples to broader _generalization_. This is also referred to as **inductive reasoning** or **inductive inference**. While it lets us to potentially be able to correctly predict the label of unseen e-mails, it also comes with possibility of false conclusions.

What distinguishes learning mechanisms that result in superstition from useful learning? This question is crucial to the development of automated learners. While human learners can rely on common sense to filter out random meaningless learning conclusions, once we export the task of learning to a machine, we must provide well defined principles that will protect the program from reaching senseless or useless conclusions. In machine learning, **inductive bias** is used  as a _set of assumptions or biases that a learning algorithm employs_ to make predictions on unseen data based on its training data. It influences how it selects a hypothesis (a possible explanation or model) from the hypothesis space (set of all hypothesis).

### Types of Inductive Bias

1. ****Bias towards simpler explanations****: Many machine learning algorithms, such as decision trees and linear models, have a bias towards simpler hypotheses. They prefer explanations that are more parsimonious and less complex, as these are often more likely to generalize well to unseen data.
2. ****Bias towards smoother functions****: Algorithms like kernel methods or Gaussian processes have a bias towards smoother functions. They assume that neighboring points in the input space should have similar outputs, leading to smooth decision boundaries.
3. ****Bias towards specific types of functions****: Neural networks, for example, have a bias towards learning complex, nonlinear functions. This bias allows them to capture intricate patterns in the data but can also lead to overfitting if not regularized properly.
4. ****Bias towards sparsity****: Some algorithms, like Lasso regression, have a bias towards sparsity. They prefer solutions where only a few features are relevant, which can improve interpretability and generalization.

## When Do We Need Machine Learning?

**Tasks That Are Too Complex to Program:** 
* For example, NP problems that can not be computed in polynomial-time. ML algorithms can be used to approximate such solutions. While exact optimal solutions can not be guaranteed, it can be used to learn patterns and heuristics to find approximate solutions faster than traditional methods.
 **Adaptability:**
* Compared to traditional solutions, ML has the ability to adapts to changed inputs and environments, and does not need to be remodeled.

## Statistical Learning Framework

**The learner’s input**: In the basic statistical learning setting, the learner has access to the following:
* **Domain Set:** An arbitrary set, $\chi$, the set of objects that we wanted to label. 
	* Usually, these domain points will be represented by a vector of features.
	* We also refer to domain points as instances and to $\chi$ as instance space.
* **Label Set:** Usually labeled set are two-elements set like ${0,1}$ or ${-1, +1}$.  Let $y$ denote our set of possible labels, where $0$ can be defined as false, and $1$ defined as true.
* **Training data**: $S=((x_1,y_1)...(x_m,y_m)$) is a finite sequence of pairs in $\chi \times y$, which stands for a sequence of labeled domain points. This is the input that the learner has access to.
	* Such labeled examples are often called training examples.
	* We sometimes also refer to S as a training set.

	**The learner’s output:** The learner is requested to output a prediction rule:
	$h : \chi \rightarrow y$, this function is also called a predictor, a hypothesis, or a classifier.
	* The predictor can be used to predict the label of new domain points. 
	* We use the notation $A(S)$ to denote the hypothesis that a learning algorithm
	* $A$, returns upon receiving the training sequence $S$.
	
	**Data Generative Model:** How the training data is generated: First we assume that the instances (objects we encountered) are generated by some probability distribution (representing the environment). Let us denote that probability distribution over $\chi$ by $D$.
	* It is important to note that we do not assume that the learner knows anything about this distribution.
	* As to the labels, in the current discussion we assume that there is some “correct” labeling function, $f : \chi \rightarrow Y$, and that $y_i = f(x_i) \forall i$.
	* The labeling function is unknown to the learner. In fact, this is just what the learner is trying to figure out.
	* In summary, each pair in the training data $S$ is generated by first sampling a point $x_i$ according to $D$ and then labeling it by $f$.
	
